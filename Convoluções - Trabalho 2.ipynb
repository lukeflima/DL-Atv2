{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import csv\n",
    "from numpy import genfromtxt\n",
    "import random\n",
    "from datetime import datetime\n",
    "random.seed(datetime.now())\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, xsize, ysize):\n",
    "    \"\"\"\n",
    "    Função para adicionar extensão por zeros na imagem de entrada.\n",
    "    Parametro: X - imagem de entrada\n",
    "    Retorno: X_pad - imagem resultante da extensão por zeros. \n",
    "    \"\"\"\n",
    "    h = X.shape[0]\n",
    "    w = X.shape[1]\n",
    "    if len(X.shape) == 3:\n",
    "        z = X.shape[2]\n",
    "        X_pad = np.concatenate((np.array([[[0]*h]*xsize]*z).T,X), axis=1)\n",
    "        X_pad = np.concatenate((X_pad,np.array([[[0]*h]*xsize]*z).T), axis=1)\n",
    "        X_pad = np.concatenate((X_pad,np.array([np.array([[0]*(w+2*xsize)]*ysize).T]*z).T), axis=0)\n",
    "        X_pad = np.concatenate((np.array([np.array([[0]*(w+2*xsize)]*ysize).T]*z).T,X_pad), axis=0)\n",
    "    else:\n",
    "        X_pad = np.concatenate(([[0]*w]*xsize,X), axis=0)\n",
    "        X_pad = np.concatenate((X_pad,[[0]*w]*xsize), axis=0)\n",
    "        X_pad = np.concatenate((X_pad,np.array([[0]*(h+2*xsize)]*ysize).T), axis=1)\n",
    "        X_pad = np.concatenate((np.array([[0]*(h+2*xsize)]*ysize).T,X_pad), axis=1)\n",
    "   \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(X,kernel,stride=1, padding=False):\n",
    "    \"\"\"\n",
    "    Função para implementar a operação de convolução.\n",
    "    Parametros: X - imagem de entrada\n",
    "                kernel - matriz com o kernel a ser utilizado pela operação\n",
    "                stride - tamanho do passo a ser utilizado (default 1)\n",
    "                padding - flag para utilização de padding (default True)\n",
    "    retorno out_conv: matriz resultante da operação de convolução\n",
    "    \"\"\"\n",
    "    #kernel = np.flip(np.flip(kernel,1),0)\n",
    "    #print((kernel*X.shape[2])[0])\n",
    "    x = X.copy()\n",
    "    rx = kernel.shape[0]//2\n",
    "    ry = kernel.shape[1]//2\n",
    "    if padding:\n",
    "        x = zero_pad(x, rx, ry)\n",
    "    if len(X.shape) == 3:\n",
    "        if len(kernel.shape) == 3:\n",
    "            out = [[np.sum(x[i-rx:i+rx+1, j-ry:j+ry+1]*kernel)\n",
    "                for j in range(ry, x.shape[1]-ry, stride)] \n",
    "                   for i in range(rx, x.shape[0]-rx, stride)]\n",
    "        else:\n",
    "            out = [[np.sum(np.sum(x[i-rx:i+rx+1, j-ry:j+ry+1], axis=2)*kernel)\n",
    "                for j in range(ry, x.shape[1]-ry, stride)] \n",
    "                   for i in range(rx, x.shape[0]-rx, stride)]\n",
    "    else:\n",
    "        out = [[np.sum(x[i-rx:i+rx+1, j-ry:j+ry+1]*(kernel)) \n",
    "                for i in range(ry, x.shape[1]-ry, stride)] \n",
    "                   for j in range(rx, x.shape[0]-rx, stride)]\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(func_type, z):\n",
    "    \"\"\"\n",
    "    Função que implementa as funções de ativação ReLU e Tanh\n",
    "    Parãmetros: func_type - uma string que contém a função de ativação desejada\n",
    "                z - matriz resultante da convolução e do bias.\n",
    "    Retorna: feature map\n",
    "    \"\"\"\n",
    "    ### Seu código aqui (~2 linhas)\n",
    "    if func_type == 'relu':\n",
    "        return np.fmax(0,z)\n",
    "    elif func_type == 'tanh':\n",
    "        return np.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_fmap(X):\n",
    "    \"\"\"\n",
    "    Função que convertendo-o para uma imagem em níveis de cinza no intervalo [0, 255], \n",
    "    com a) níveis em valor absoluto com preto = zero; e b) mínimo = preto.\n",
    "    \"\"\"\n",
    "    x = X.copy()\n",
    "    x = np.abs(x) \n",
    "    x = np.array(x*255/x.max()).astype('uint8')\n",
    "    plt.imshow(x, 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convLayer(X,act_func, filters, bias, stride=1, padding=False):\n",
    "    \"\"\"\n",
    "    Implementa a camada convolucional utilizando bias e função de ativação.\n",
    "    Parametros: X - matriz de entrada\n",
    "                C - quantidade de canais do feature map\n",
    "                filters - filtros utilizados na camada\n",
    "                stride - tamanho do passo a ser utilizado (default 1)\n",
    "                padding - flag para utilização de padding (default True)\n",
    "    Retorno: fmap - feature map de dimensão (n_W,n_H, C)\n",
    "    \"\"\"\n",
    "    fmap = np.array([convolution(X,f,stride,padding) for f in filters])\n",
    "    fmap = np.array([activation_func(act_func, f + b) for f,b in zip(fmap, bias)])\n",
    "    return fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file):\n",
    "    f = open(file, \"r\")\n",
    "    size = np.array(f.readline().strip().split(',')).astype('int')\n",
    "    aux = [i.strip() for i in f.readlines() if i is not \"\\n\"]\n",
    "    bias = np.array(aux[-1].split(',')).astype('double')\n",
    "    del aux[-1]\n",
    "    kernels = np.array([np.array(i.split(',')).astype('double').reshape(size) for i in aux])\n",
    "    kernels.shape\n",
    "    return kernels, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPooling(x):\n",
    "    if len(x.shape) < 3 and x.shape[-1] is not 1:\n",
    "        out = [[np.max(x[i-1:i+2, j-1:j+2])\n",
    "                for j in range(1, x.shape[1], 2)] \n",
    "                   for i in range(1, x.shape[0], 2)]\n",
    "    else:\n",
    "        out = [[[np.max(k[i-1:i+2, j-1:j+2])\n",
    "                for j in range(1, k.shape[1], 2)] \n",
    "                   for i in range(1, k.shape[0], 2)] \n",
    "                       for k in x]\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file, img):\n",
    "    convFilters, bias = readFile(file)\n",
    "    stride = int(input(\"Entre com um valor inteiro positivo para o stride \"))\n",
    "    padding = (input(\"Sua operaçao será feita com padding? True or False \"))\n",
    "    imageFile = np.asarray(Image.open(img))\n",
    "    plt.imshow(imageFile) \n",
    "    plt.show()\n",
    "    fmap = convLayer(imageFile,'relu', convFilters, bias, stride, padding)\n",
    "    for f in fmap:\n",
    "        visualize_fmap(f)\n",
    "    #fmap2 = fmap.swapaxes(0,2).swapaxes(0,1)\n",
    "    #fmap2 = convLayer(fmap2,'relu', convFilters, bias, stride, padding)\n",
    "    #print(\"-\"*80)\n",
    "    #for f in fmap2:\n",
    "       # visualize_fmap(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1875, 32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "def grouper(n, iterable, padvalue=None):\n",
    "    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n",
    "    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)\n",
    "\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train = np.array([zero_pad(x,2,2) for x in x_train])\n",
    "x_test = np.array([zero_pad(x,2,2) for x in x_test])\n",
    "#data suffling\n",
    "p = np.random.permutation(x_train.shape[0])\n",
    "x_train = x_train[p]\n",
    "y_train = y_train[p]\n",
    "#batch creation and normalization\n",
    "a = np.array([np.array(list(i)) for i in grouper(32, x_train)])\n",
    "ybatchs = np.array([np.array(list(i)) for i in grouper(32, y_train)])\n",
    "print(a.shape)\n",
    "batchs = np.array([(x - u) / d for x, u, d in zip(a, np.mean(a, axis=(1,2,3)), np.std(a, axis=(1,2,3)))])\n",
    "\n",
    "plt.imshow(batchs[1][1], 'gray') \n",
    "plt.show()\n",
    "print(maxPooling(batchs[1][0]).shape)\n",
    "plt.imshow(maxPooling(batchs[1][0]),'gray')\n",
    "plt.show()\n",
    "print(ybatchs[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# He\n",
    "def He(currLayer_size, prevLayer_size, currKernel_size):\n",
    "    return np.array(\n",
    "        [np.random.standard_normal(size = currLayer_size) * np.sqrt(2/prevLayer_size) \n",
    "                     for _ in range(currKernel_size)])\n",
    "    \n",
    "def randomWeights():\n",
    "    kernelsizes = [(5,5), (5,5,6), (5,5,16), (120), (84)]\n",
    "    layersizes = [6,6,16,120,84,10]\n",
    "\n",
    "    kernels = np.array([np.array(He(kernelsizes[s], layersizes[k], layersizes[k+1])) \n",
    "                        for s, k in zip(range(len(kernelsizes)), range(len(layersizes)))])\n",
    "    bias = np.array(\n",
    "        [He(1, layersizes[i], layersizes[i+1]) for i in range(len(layersizes)-1) ])\n",
    "    #bias[3].shape\n",
    "    return kernels, bias\n",
    "\n",
    "kernels, bias = randomWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softMax(x):\n",
    "#     import bigfloat\n",
    "#     xexp = np.array([bigfloat.exp(i,bigfloat.precision(200)) for i in x])\n",
    "#     return xexp / np.sum(xexp)\n",
    "    exp = np.exp(x)\n",
    "    return exp / exp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lost(f, y):\n",
    "    return -np.log(f[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lenet\n",
    "def lenet(img):\n",
    "    fmap = convLayer(img,'relu', kernels[0], bias[0])\n",
    "    fmap = maxPooling(fmap).swapaxes(0,2).swapaxes(0,1)\n",
    "    fmap = convLayer(fmap,'relu', kernels[1], bias[1])\n",
    "    fmap = maxPooling(fmap).swapaxes(0,2).swapaxes(0,1)\n",
    "    fmap = convLayer(fmap,'relu', kernels[2], bias[2])\n",
    "    fmap = fmap.flatten()\n",
    "    fmap = np.array([np.sum(fmap*w)  for w in kernels[3]] + bias[3].flatten())\n",
    "    fmap = activation_func(\"relu\", fmap)\n",
    "    fmap = np.array([np.sum(fmap*w)  for w in kernels[4]] + bias[4].flatten())\n",
    "    fmap = softMax(fmap)\n",
    "    return fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339.54430773357296\n"
     ]
    }
   ],
   "source": [
    "x = 52\n",
    "y = 31\n",
    "f = lenet(batchs[x][y])\n",
    "perda = lost(f, ybatchs[x][y])\n",
    "print(perda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleBatchs = batchs[:2]\n",
    "sampleyBatchs = ybatchs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.0046502027693\n",
      "159.00472297442764                                                              \n",
      "113.02488773637084                                                              \n",
      "0.0%                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pichau\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n",
      "c:\\users\\pichau\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "c:\\users\\pichau\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.154166666666665%                                                             \r"
     ]
    }
   ],
   "source": [
    "step_size = 1e-2\n",
    "d = 1e-4\n",
    "weights = kernels.ravel()\n",
    "allBatchs = np.array([[lenet(i) for i in batch] for batch in sampleBatchs])\n",
    "y_pred = allBatchs.argmax(axis=2)\n",
    "#accuracys.append(np.equal(np.argmax(sampleyBatchs, axis=-1), np.argmax(y_pred, axis=-1)).mean())\n",
    "perda = np.array([[lost(b, y) for b, y in zip(allBatch, ybatch)] for allBatch, ybatch in zip(allBatchs, sampleyBatchs)]).mean()\n",
    "print(perda)\n",
    "for _ in range(100):\n",
    "    for k in range(kernels.size):\n",
    "        accuracys = []\n",
    "        perdas = []\n",
    "        i = 0\n",
    "        sizek = kernels.flat[k].flatten().size\n",
    "        for w in range(sizek):\n",
    "            print(\" \"*80, end=\"\\r\")\n",
    "            print(f\"{i*100/sizek}%\", end=\"\\r\")\n",
    "            i = i + 1\n",
    "            kernels.flat[k].flat[w] = kernels.flat[k].flat[w] + d\n",
    "            allBatchs = np.array([[lenet(i) for i in batch] for batch in sampleBatchs])\n",
    "            y_pred = allBatchs.argmax(axis=2)\n",
    "            accuracys.append(np.equal(np.argmax(sampleyBatchs, axis=-1), np.argmax(y_pred, axis=-1)).mean())\n",
    "            perdas.append(np.array([[lost(b, y) for b, y in zip(allBatch, ybatch)] for allBatch, ybatch in zip(allBatchs, sampleyBatchs)]).mean())\n",
    "            kernels.flat[k].flat[w] = kernels.flat[k].flat[w] - d\n",
    "            print(\" \"*80, end=\"\\r\")\n",
    "            print(f\"{i*100/sizek}%\", end=\"\\r\")\n",
    "        print(\" \"*80, end=\"\\r\")\n",
    "        dperdas = (np.array(perdas) - perda)/d\n",
    "        #minPerda = np.argmax(np.abs(dperdas))\n",
    "        #print(perdas)\n",
    "        for p in range(sizek):\n",
    "            kernels.flat[k].flat[p] = kernels.flat[k].flat[p] - dperdas[p]*step_size\n",
    "        print(perdas[minPerda])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.26921028923228235"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "kernels.flat[0].flat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 84)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
